{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Installs Unsloth, Xformers (Flash Attention) and all other packages\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps xformers trl peft accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "MCesRu0uwlgA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7WKtAWNwGeU",
        "outputId": "ef212214-0f54-4936-c374-1996d96681cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from unsloth import FastLanguageModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt template\n",
        "prompt_template = \"\"\"<s>[INST] <<SYS>>\n",
        "You are an insightful financial analyst with a knack for interpreting news. Respond concisely in one sentence starting with a dynamic phrase like:\n",
        "{opening_line}\n",
        "<</SYS>>\n",
        "{user_input} (Sentiment - {sentiment}) [/INST]\n",
        "\n",
        "###Response:==>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RqGwH7i7wggY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of 15 opening phrases\n",
        "opening_phrases = [\n",
        "    \"The sentiment around this news is {sentiment} because...\",\n",
        "    \"This headline conveys a {sentiment} sentiment because...\",\n",
        "    \"From a financial perspective, this reflects a {sentiment} sentiment because...\",\n",
        "    \"The tone of this news is {sentiment} because...\",\n",
        "    \"Market analysts interpret this as a {sentiment} sentiment because...\",\n",
        "    \"This news indicates a {sentiment} sentiment because...\",\n",
        "    \"The mood around this news is {sentiment} because...\",\n",
        "    \"This update reflects a {sentiment} sentiment due to...\",\n",
        "    \"The implications of this news are {sentiment} because...\",\n",
        "    \"Financially, this signals a {sentiment} sentiment because...\",\n",
        "    \"The perception of this news is {sentiment} because...\",\n",
        "    \"This event highlights a {sentiment} sentiment because...\",\n",
        "    \"From an analytical viewpoint, this is a {sentiment} sentiment because...\",\n",
        "    \"The narrative around this news points to a {sentiment} sentiment because...\",\n",
        "    \"The overall impression of this news is {sentiment} because...\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "DkC4-07dwuet"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to dynamically generate the prompt\n",
        "def generate_dynamic_prompt(user_input, sentiment):\n",
        "    # Select a random opening phrase\n",
        "    opening_line = random.choice(opening_phrases).format(sentiment=sentiment)\n",
        "    # Generate the formatted prompt\n",
        "    return prompt_template.format(opening_line=opening_line, user_input=user_input, sentiment=sentiment)\n",
        "\n",
        "# Example function to process the dataset\n",
        "def generate_response(sentence, sentiment):\n",
        "    # Generate a dynamic prompt\n",
        "    prompt = generate_dynamic_prompt(sentence, sentiment)\n",
        "    # Tokenize and generate response\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=100, use_cache=True)\n",
        "    response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    # Extract the final response\n",
        "    split_response = response.split(\"###Response:==>\")\n",
        "    if len(split_response) > 1:\n",
        "        filtered_output = split_response[1].strip().split('.')[0].strip()\n",
        "        return filtered_output\n",
        "    return 'No response found'\n"
      ],
      "metadata": {
        "id": "vzYBUmxuw6Ue"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the dataset\n",
        "file_path = \"sentiment_data.csv\"  # Replace with your dataset path\n",
        "data = pd.read_csv(file_path)\n",
        "data.columns = data.columns.str.strip().str.lower()  # Normalize column names"
      ],
      "metadata": {
        "id": "HDJiV5e0xDgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate dataset columns\n",
        "if \"sentence\" not in data.columns or \"sentiment\" not in data.columns:\n",
        "    print(\"Columns found in dataset:\", data.columns)\n",
        "    raise ValueError(\"The dataset must contain 'sentence' and 'sentiment' columns.\")"
      ],
      "metadata": {
        "id": "hYlQvEVbxFZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each row and generate responses\n",
        "results = []\n",
        "for _, row in data.iterrows():\n",
        "    sentence = row[\"sentence\"]\n",
        "    sentiment = row[\"sentiment\"]\n",
        "    response = generate_response(sentence, sentiment)\n",
        "    print(f\"Sentence: {sentence}\\nSentiment: {sentiment}\\nResponse: {response}\\n\")\n",
        "    results.append({\"sentence\": sentence, \"sentiment\": sentiment, \"response\": response})\n"
      ],
      "metadata": {
        "id": "rd9DY64Rxozc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results to a CSV file\n",
        "output_file = \"responses.csv\"\n",
        "result_df = pd.DataFrame(results)\n",
        "result_df.to_csv(output_file, index=False)\n",
        "print(f\"Responses saved to {output_file}\")"
      ],
      "metadata": {
        "id": "zu_BlnrVxrTv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}